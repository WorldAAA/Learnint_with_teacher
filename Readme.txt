Описание проекта
Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.
Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 
Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно.
Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой.


Описание данных
Данные находятся в файле Churn.csv (англ. «отток клиентов»). 
Признаки
RowNumber — индекс строки в данных
CustomerId — уникальный идентификатор клиента
Surname — фамилия
CreditScore — кредитный рейтинг
Geography — страна проживания
Gender — пол
Age — возраст
Tenure — сколько лет человек является клиентом банка
Balance — баланс на счёте
NumOfProducts — количество продуктов банка, используемых клиентом
HasCrCard — наличие кредитной карты
IsActiveMember — активность клиента
EstimatedSalary — предполагаемая зарплата
Целевой признак
Exited — факт ухода клиента

Описания проекта
В процессе выполнения данной проектной работы:
был открыт и изучен исследуемый датасет на предмет неверных типов данных, отсутствующих данных, логических ошибок в данных;
строки с отсутствующими важными данными (с информацией сколько лет человек является клиентом банка) были удалены;
перед обучением моделей, были исключены ненужные для модели данные, а категориальные признаки заменены численными по принципу OHE;
анализ баланса классов показал дисбаланс между положительным/отрицательным целевым признаком в 3.9 раза;
обучение моделей без учета дисбаланса и поиск наилучших комбинаций параметров. В итоге лучшая модель из тройки Решающее дерево/Случайный лес/Логистическая регрессия - Случайный лес. Но целевое значение F1 на данной выборке достигнуто не было. Auc-roc модели высоки;
проблема дисбаланса данных решалась методами даунсемплинга и апсемплинга. Более высокие результаты модели показывали при апсемплинге в выборке, а победительницей снова стала модель случайного леса, на этот раз превысившая целевое значение F1;
тестирование лучшей модели подтвердило ее дееспособность - результаты F1 и Auc-roc незначительно изменились относительно результатов на валидационной выборке и также превысили целевое значение в 0.59 для F1